Azure:
- Tydzień 7: Pogłębienie dokumentacji (Identity, Governance, Monitoring, IaC)
- Tydzień 7: Testy praktyczne AZ-900 (analiza wyników)
- Tydzień 7: Utrwalanie Zero-Trust / Defense in Depth / Azure Policy
- Tydzień 7: Przygotowanie posta #4 (Identity & Access Management)
- Tydzień 7: Planowanie terminu egzaminu (koniec IX / X)
- Tydzień 3: Podstawy usług chmurowych
- Tydzień 3: Poznanie interfejsu Azure Portal
- Tydzień 3: Przygotowanie do certyfikatu AZ-900

Docker:
- Podstawy pisania dockerfiles (Tydzień 3)
- Konteneryzacja aplikacji (Tydzień 2)
- Zarządzanie obrazami Docker (Tydzień 2)

MongoDB:
- Pierwszy kontakt z bazami NoSQL (Tydzień 3)
- Środowisko MongoDB Compass (Tydzień 3)
- Planowanie MongoDB Atlas w Azure (Tydzień 3)

GitHub Actions:
- Pierwsze workflow YAML (Tydzień 2)
- Automatyzacja build/run JS app (Tydzień 2)
- CI/CD podstawy (Tydzień 2)

Railway:
- Deployment do chmury (Tydzień 2)
- Konfiguracja cron jobs (Tydzień 2)
- Automatyzacja deploymentów (Tydzień 2)

Bash/Linux:
- Podstawy poleceń Linux (W trakcie)
- Windows Terminal/PowerShell (W trakcie)
- SSH i podstawy networking (W trakcie)

Python:
- Wykorzystanie w projektach DevOps (W trakcie)
- Automatyzacja zadań (W trakce)
- Integracja z bazami danych (W trakcie)


Fundamenty pod projekt – Data Science / AI:

- Tydzień 9: Zarządzanie czasem – plan dnia pod studia, LinkedIn i naukę
- Tydzień 9: Priorytety i higiena pracy – eliminacja rozpraszaczy, odpoczynek
- Tydzień 9: Plan na październik – migracja postępów do zadań uczelnianych + biuletyn
- Tydzień 9: Seria Azure – ostatni post edukacyjny (domknięcie serii) + budowa fundamentów pod analizę emocji w tekście (pierwszy artykuł w piątek)
- Tydzień 8: Środowisko (Anaconda, Jupyter, Conda) – przygotowanie do pracy z NLP
- Tydzień 8: Preprocessing (Pandas, spaCy) – czyszczenie i obróbka tekstu
- Tydzień 8: Vectorization (Count, TF-IDF) – zamiana tekstu na liczby dla modeli
- Tydzień 8: Sentiment Analysis – analiza nastroju w tekście
- Tydzień 8: Text Classification (Naïve Bayes) – kategoryzacja tekstów ML-em
- Tydzień 8: Topic Modeling (NMF) – wykrywanie tematów w zbiorach tekstów
- Tydzień 7: Koncepcja i zakres projektu
- Tydzień 7: Źródła danych (posty, komentarze, newsy)
- Tydzień 7: Wybór stosu technologicznego (Python, Azure Functions/Storage)
- Tydzień 7: Plan pipeline: pobieranie -> czyszczenie -> NLP -> insighty
- Tydzień 7: Metryki: sentiment score, trend, intensywność emocji
- Tydzień 7: Roadmapa MVP + iteracje
- Tydzień 7: Research bibliotek (Transformers, spaCy, nltk)
- Tydzień 7: Plan walidacji i prezentacji wyników

Studia:

- Tydzień 9: Powrót na uczelnię – sprawy kwaterunkowe i organizacyjne
- Tydzień 9: Plan zarządzania czasem (blokowe uczenie, odpoczynek, priorytety)
- Tydzień 9: Łączenie postępów z zadaniami na uczelni (od przyszłego tygodnia)
- Tydzień 9: Start biuletynu – informatyka + dobrostan psychiczny; przedmioty: Praktyczne wykorzystanie bibliotek Pythona (pandas, numpy, matplotlib, scikit-learn, Titanic Dataset, Jupyter Notebook), Usługi DevOps [CKA] (Docker, obrazy, kontenery, CLI), Wirtualizacja i konteneryzacja (Rocky Linux, konfiguracja zasobów, SSH, podman/kubectl/minikube, klaster Kubernetes)
Tydzień 10 - Studia: Praktyczne wykorzystanie bibliotek Pythona
- Obsługa bibliotek: pandas, numpy, matplotlib, scikit-learn
- Wczytywanie i analiza danych z plików CSV
- Czyszczenie i przygotowanie danych do modeli ML
- Tworzenie modeli predykcyjnych i eksport wyników
- Praca w środowisku Jupyter Notebook
- Analiza danych na podstawie zbioru Titanic Dataset – przygotowanie danych, trenowanie modelu, tworzenie pliku submission.csv z wynikami

Tydzień 10 - Studia: Usługi DevOps [CKA]
- Instalacja i konfiguracja środowiska Docker
- Tworzenie i uruchamianie kontenerów z obrazów
- Praca z podstawowymi poleceniami Docker CLI
- Zrozumienie pojęć: kontener, obraz, rejestr
- Praktyczne zastosowanie konteneryzacji do uruchamiania aplikacji

Tydzień 10 - Studia: Wirtualizacja i konteneryzacja
- Instalacja systemu Rocky Linux w VirtualBox
- Konfiguracja maszyny wirtualnej (RAM, CPU, sieć, dysk)
- Logowanie do maszyny przez SSH (PuTTY)
- Instalacja niezbędnych narzędzi: podman, kubectl, minikube
- Uruchomienie klastra Kubernetes na Rocky Linux
